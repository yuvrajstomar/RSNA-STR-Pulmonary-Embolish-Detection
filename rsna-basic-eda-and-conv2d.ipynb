{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install pydicom\n#conda install plotly\nconda install scikit-image\n\n%matplotlib inline\n\nimport numpy as np\nimport pandas as pd\nfrom os import listdir, mkdir\nimport matplotlib.pyplot as plt\nfrom glob import glob #Use Unix shell rules to fine filenames matching a pattern\n#from mpl_toolkits.mplot3d.art3d import Poly3DCollection #dealing with 3d polygons\n#import scipy.ndimage\n#from skimage import morphology #to deal with shape of features in an image\n#from skimage import measure\n#from skimage.transform import resize\n#from sklearn.cluster import KMeans\n#from plotly import __version__\n#from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n#from plotly.tools import FigureFactory as FF\n#from plotly.graph_objs import *\n#init_notebook_mode(connected=True) \n\nfrom zipfile import ZipFile\nfrom keras.layers import Input, Lambda, Dense, Flatten\nfrom tensorflow.python.keras.layers import Dense,Conv2D, MaxPooling2D, Flatten, BatchNormalization, Dropout\nfrom keras.models import Model\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.preprocessing import image\nfrom keras.models import Sequential\nfrom keras.preprocessing.image import ImageDataGenerator\nimport keras\nimport tensorflow as tf\nfrom PIL import ImageFile","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"listdir(\"../input/\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"basepath = \"../input/rsna-str-pulmonary-embolism-detection/\"\n\ntrain = pd.read_csv(basepath + \"train.csv\")\ntest = pd.read_csv(basepath + \"test.csv\")\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Setting dcm file path as new column in our dataframe:\n#train[\"dcm_path\"] = basepath + \"train/\" + train.StudyInstanceUID + \"/\" + train.SeriesInstanceUID+ \"/\"\n#test[\"dcm_path\"] = basepath + \"test/\" + test.StudyInstanceUID + \"/\" + test.SeriesInstanceUID+ \"/\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pydicom\ndef load_scans(dcm_path):\n    # otherwise we sort by ImagePositionPatient (z-coordinate) or by SliceLocation\n    slices = [pydicom.dcmread(dcm_path + \"/\" + file) for file in listdir(dcm_path)]\n    slices.sort(key = lambda x: float(x.ImagePositionPatient[2]))\n    return slices\n\n#lets see details for first patient:\nexample = train.dcm_path.values[0]\nscans = load_scans(example)\nscans","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nfig, ax = plt.subplots(1,2,figsize=(20,5))\nfor n in range(30):\n    image = scans[n].pixel_array.flatten()\n    rescaled_image = image * scans[n].RescaleSlope + scans[n].RescaleIntercept\n    sns.distplot(image.flatten(), ax=ax[0]);\n    sns.distplot(rescaled_image.flatten(), ax=ax[1])\nax[0].set_title(\"Raw pixel array distributions for 10 examples\")\nax[1].set_title(\"HU unit distributions for 10 examples\");\n#For some examples we can see that there are raw values at -2000. They correspond to images with a circular boundary within the image. \n#The \"outside\" of this circle value is often set to -2000\n\ndef set_outside_scanner_to_air(raw_pixelarrays):\n    # in OSIC we find outside-scanner-regions with raw-values of -2000. \n    # Let's threshold between air (0) and this default (-2000) using -1000\n    raw_pixelarrays[raw_pixelarrays <= -1000] = 0\n    return raw_pixelarrays\n\n#transformation to HU:\n\ndef transform_to_hu(slices):\n    images = np.stack([file.pixel_array for file in slices])\n    images = images.astype(np.int16)\n\n    images = set_outside_scanner_to_air(images)\n    \n    # convert to HU\n    for n in range(len(slices)):\n        \n        intercept = slices[n].RescaleIntercept\n        slope = slices[n].RescaleSlope\n        \n        if slope != 1:\n            images[n] = slope * images[n].astype(np.float64)\n            images[n] = images[n].astype(np.int16)\n            \n        images[n] += np.int16(intercept)\n    \n    return np.array(images, dtype=np.int16)\n\nhu_scans = transform_to_hu(scans)\nhu_scans[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_pixels_hu(scans):\n    image = np.stack([s.pixel_array for s in scans])\n    # Convert to int16 (from sometimes int16), \n    # should be possible as values should always be low enough (<32k)\n    image = image.astype(np.int16)\n\n    # Set outside-of-scan pixels to 1\n    # The intercept is usually -1024, so air is approximately 0\n    image[image == -2000] = 0\n    \n    # Convert to Hounsfield units (HU)\n    intercept = scans[0].RescaleIntercept\n    slope = scans[0].RescaleSlope\n    \n    if slope != 1:\n        image = slope * image.astype(np.float64)\n        image = image.astype(np.int16)\n        \n    image += np.int16(intercept)\n    \n    return np.array(image, dtype=np.int16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import glob\ntrain_image_file_paths = glob.glob(basepath+'train/' + '/*/*/*.dcm')\ntest_image_file_paths = glob.glob(basepath +'test/'+ '/*/*/*.dcm')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#type(train_image_file_paths)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to take care of teh translation and windowing. \ndef window_image(img, window_center,window_width, intercept, slope, rescale=True):\n    img = (img*slope +intercept) #for translation adjustments given in the dicom file. \n    img_min = window_center - window_width//2 #minimum HU level\n    img_max = window_center + window_width//2 #maximum HU level\n    img[img<img_min] = img_min #set img_min for all HU levels less than minimum HU level\n    img[img>img_max] = img_max #set img_max for all HU levels higher than maximum HU level\n    if rescale: \n        img = (img - img_min) / (img_max - img_min)*255.0 \n    return img\n\ndef get_first_of_dicom_field_as_int(x):\n    #get x[0] as in int is x is a 'pydicom.multival.MultiValue', otherwise get int(x)\n    if type(x) == pydicom.multival.MultiValue: return int(x[0])\n    else: return int(x)\n    \ndef get_windowing(data):\n    dicom_fields = [data[('0028','1050')].value, #window center\n                    data[('0028','1051')].value, #window width\n                    data[('0028','1052')].value, #intercept\n                    data[('0028','1053')].value] #slope\n    return [get_first_of_dicom_field_as_int(x) for x in dicom_fields]\n\ndef view_images(files, title = '', aug = None, windowing = True):\n    width = 2\n    height = 2\n    fig, axs = plt.subplots(height, width, figsize=(15,15))\n    \n    for im in range(0, height * width):\n        data = pydicom.dcmread(files[im])\n        image = data.pixel_array\n        window_center , window_width, intercept, slope = get_windowing(data)\n        if windowing:\n            output = window_image(image, window_center, window_width, intercept, slope, rescale = False)\n        else:\n            output = image\n        i = im // width\n        j = im % width\n        axs[i,j].imshow(output, cmap=plt.cm.gray) \n        axs[i,j].axis('off')\n        \n    plt.suptitle(title)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"view_images(train_image_file_paths[3205:], 'Images with Windowing')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"view_images(train_image_file_paths)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_image_file_paths[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"listdir(directory)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#remove folder\n#from pathlib import Path\n#import shutil\n\n#dirpath = Path('train_imgs')\n#if dirpath.exists() and dirpath.is_dir():\n#    shutil.rmtree(dirpath)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"#creating a copy of images in new subfolder\nimport glob \nimport shutil\n\n    \ndestination_path = \"test_imgs_folder\"\nos.mkdir(destination_path)\npattern = \"../input/rsna-str-pulmonary-embolism-detection/test/*/*/*\"  \nfor img in glob.glob(pattern):\n    shutil.copy(img, destination_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"destination_path = \"train_imgs_folder\"\nos.mkdir(destination_path)\npattern = \"../input/rsna-str-pulmonary-embolism-detection/train/*/*/*\"  \nfor img in glob.glob(pattern):\n    shutil.copy(img, destination_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#move all the train images to one folder\n#import os\n#import cv2\n\n#directory = '../input/rsna-str-pulmonary-embolism-detection/train'\n#new_directory = 'train_imgs_folder'\n\n# If dir does not exist otherwise delete next line\n#os.mkdir(new_directory)\n\n#def copy_images():\n#    for file_name in train_image_file_paths:\n#        img = cv2.imread(file_name[-17:])\n#        copied_image_path = new_directory + '/' + file_name\n#        cv2.imwrite(copied_image_path, img)\n\n#copy_images()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n#ImageDataGenerator helps in Image Augmentation. IMAGE_SIZE will be used in VGG, ResNet implementation to resize image\n#s=32\nIMAGE_SIZE = [224, 224]\n#set validation split\ntrainGen=ImageDataGenerator(rescale=1./255,shear_range= 0.2,zoom_range= 0.2,horizontal_flip= True,rotation_range= 40,width_shift_range = 0.2,height_shift_range = 0.2)\n\ntestGen = ImageDataGenerator(rescale=1./255)\n\ntrain_imgs = trainGen.flow_from_directory('train_imgs_folder', class_mode='binary', batch_size=32)\ntest_imgs = testGen.flow_from_directory('test_imgs_folder', class_mode='binary', batch_size=32)\n\n#train_datagen = ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2, horizontal_flip=True, validation_split=0.2) # set validation split\n\n# same directory as training data\n#train_generator = train_datagen.flow_from_directory( train_data_dir,target_size=(img_height, img_width),batch_size=batch_size,class_mode='binary',subset='training') # set as training data\n# set as validation data\n#validation_generator = train_datagen.flow_from_directory(train_data_dir, target_size=(img_height, img_width),batch_size=batch_size,class_mode='binary',subset='validation') \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = ['qa_motion','qa_contrast','flow_artifact','true_filling_defect_not_pe']\ntrain = train.drop(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#Building CNN model:\nmodel = Sequential()\n\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64,64,3), padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation = 'relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation = 'sigmoid'))\nmodel.summary()\n#Lets tell the model what cost and optimization method to use and fit the model to our training data set\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n# Run the cell. It will take some time to execute\n\n\n#r= model.fit_generator(train_generator,steps_per_epoch = train_generator.samples // batch_size,validation_data = validation_generator, validation_steps = validation_generator.samples // batch_size,epochs = 100)\n\n\n#r = model.fit_generator(train_set,validation_data=val_set,epochs=5,steps_per_epoch=len(train_set),validation_steps=len(test_set))\n\nmodel.fit(train_imgs, train, batch_size = 32, epochs = 100)\nmodel.save('model.h1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test_accuracy = model.evaluate_generator(test,steps=None)\n\n#print('Testing Accuracy-CNN: {:.2f}%'.format(test_accuracy[1] * 100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#classes = model.predict_classes(images, batch_size=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}