{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"conda install python=3.7","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"conda install -c conda-forge gdcm -y","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"%matplotlib inline\n\nimport numpy as np\nimport pandas as pd\nfrom os import listdir, mkdir\nimport matplotlib.pyplot as plt\nfrom glob import glob \nfrom zipfile import ZipFile\nfrom keras.models import Sequential\nimport keras\nimport tensorflow as tf\nfrom keras.layers import Input, Lambda, Dense, Flatten\nfrom tensorflow.python.keras.layers import Dense,Conv2D, MaxPooling2D, Flatten, BatchNormalization, Dropout\nfrom keras.models import Model\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.preprocessing import image\nfrom keras.models import Sequential\nfrom keras.preprocessing.image import ImageDataGenerator\nimport pydicom\nimport gdcm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"basepath = \"../input/rsna-str-pulmonary-embolism-detection/\"\ntrain = pd.read_csv(basepath+\"train.csv\")\ntest = pd.read_csv(basepath+\"test.csv\")\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.drop(['qa_motion','qa_contrast','flow_artifact','true_filling_defect_not_pe'] , 1)\ntrain.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Building CNN model:\nmodel = Sequential()\n\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(256,256,3), padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation = 'relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(1, activation = 'sigmoid'))\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets tell the model what cost and optimization method to use and fit the model to our training data set\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Train data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nPathDicom_train = basepath+\"train/\"\nlstFilesDCM_train = []  # create an empty list\ncount = 0\nfor dirName, subdirList, fileList in os.walk(PathDicom_train):\n    for filename in fileList:\n        if \".dcm\" in filename.lower() and count<5000:  # check whether the file's DICOM\n            lstFilesDCM_train.append(os.path.join(dirName,filename))\n        else:\n            break\n        count+=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get ref file\nRefDs = pydicom.read_file(lstFilesDCM_train[0])\n\n# Load dimensions based on the number of rows, columns, and slices (along the Z axis)\nConstPixelDims = (int(RefDs.Rows), int(RefDs.Columns), len(lstFilesDCM_train))\n\n# Load spacing values (in mm)\nConstPixelSpacing = (float(RefDs.PixelSpacing[0]), float(RefDs.PixelSpacing[1]), float(RefDs.SliceThickness))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = np.arange(0.0, (ConstPixelDims[0]+1)*ConstPixelSpacing[0], ConstPixelSpacing[0])\ny = np.arange(0.0, (ConstPixelDims[1]+1)*ConstPixelSpacing[1], ConstPixelSpacing[1])\nz = np.arange(0.0, (ConstPixelDims[2]+1)*ConstPixelSpacing[2], ConstPixelSpacing[2])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"#os.chdir('patil.shru/')\n# The array is sized based on 'ConstPixelDims'\nArrayDicom_train = np.zeros(ConstPixelDims, dtype=RefDs.pixel_array.dtype)\n\n# loop through all the DICOM files\nfor filenameDCM in lstFilesDCM_train:\n    # read the file\n    ds = pydicom.read_file(filenameDCM)\n    # store the raw image data\n    ArrayDicom_train[:, :, lstFilesDCM_train.index(filenameDCM)] = ds.pixel_array\n    ArrayDicom_train=ArrayDicom_train.astype('float32').tobytes()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Test data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"PathDicom_test = basepath+\"test\"\nlstFilesDCM_test = []  # create an empty list\nfor dirName, subdirList, fileList in os.walk(PathDicom_test):\n    for filename in fileList:\n        if \".dcm\" in filename.lower() and count<10000:  # check whether the file's DICOM\n            lstFilesDCM_test.append(os.path.join(dirName,filename))\n        else:\n            break\n        count+=1\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get ref file\nRefDs = pydicom.read_file(lstFilesDCM_test[0])\n\n# Load dimensions based on the number of rows, columns, and slices (along the Z axis)\nConstPixelDims = (int(RefDs.Rows), int(RefDs.Columns), len(lstFilesDCM_test))\n\n# Load spacing values (in mm)\nConstPixelSpacing = (float(RefDs.PixelSpacing[0]), float(RefDs.PixelSpacing[1]), float(RefDs.SliceThickness))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The array is sized based on 'ConstPixelDims'\nArrayDicom_test = np.zeros(ConstPixelDims, dtype=RefDs.pixel_array.dtype)\n\n# loop through all the DICOM files\nfor filenameDCM in lstFilesDCM_test:\n    # read the file\n    ds = pydicom.read_file(filenameDCM)\n    # store the raw image data\n    ArrayDicom_test[:, :, lstFilesDCM_test.index(filenameDCM)] = ds.pixel_array ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from keras.preprocessing.image import ImageDataGenerator\n#ImageDataGenerator helps in Image Augmentation. IMAGE_SIZE will be used in VGG, ResNet implementation to resize image\n#s=32\n#IMAGE_SIZE = [224, 224]\n#set validation split\n#trainGen=ImageDataGenerator(rescale=1./255,shear_range= 0.2,zoom_range= 0.2,horizontal_flip= True,rotation_range= 40,width_shift_range = 0.2,height_shift_range = 0.2)\n\n#testGen = ImageDataGenerator(rescale=1./255)\n\n#train_imgs = trainGen.flow_from_directory('ArrayDicom_train', class_mode='categorical', batch_size=32)\n#test_imgs = testGen.flow_from_directory('lstFilesDCM_test', class_mode='binary', batch_size=32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_sub = train.head(512)\ntrain_sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(ArrayDicom_train, train_sub, batch_size = 32, epochs = 100)\nmodel.save('model.h1')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}